{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading, visualizing, and preprocessing data\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklear.prepressing import Imputer\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>uup</th>\n",
       "      <th>gdp</th>\n",
       "      <th>prod</th>\n",
       "      <th>vader</th>\n",
       "      <th>textblob_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>734016</td>\n",
       "      <td>734016</td>\n",
       "      <td>23.19</td>\n",
       "      <td>99.65</td>\n",
       "      <td>5562.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>734017</td>\n",
       "      <td>734017</td>\n",
       "      <td>23.17</td>\n",
       "      <td>99.65</td>\n",
       "      <td>5563.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>734018</td>\n",
       "      <td>734018</td>\n",
       "      <td>23.05</td>\n",
       "      <td>99.66</td>\n",
       "      <td>5564.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>734019</td>\n",
       "      <td>734019</td>\n",
       "      <td>23.11</td>\n",
       "      <td>99.66</td>\n",
       "      <td>5565.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>734020</td>\n",
       "      <td>734020</td>\n",
       "      <td>23.18</td>\n",
       "      <td>99.66</td>\n",
       "      <td>5566.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   price    uup    gdp     prod  vader  textblob_polarity\n",
       "3045  734016  734016  23.19  99.65  5562.00   0.26              -0.00\n",
       "3046  734017  734017  23.17  99.65  5563.03   0.25              -0.01\n",
       "3047  734018  734018  23.05  99.66  5564.07   0.25              -0.01\n",
       "3048  734019  734019  23.11  99.66  5565.10   0.24              -0.02\n",
       "3049  734020  734020  23.18  99.66  5566.13   0.23              -0.02"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = Path('wl/df_all.csv')\n",
    "s_path = Path('Data/df_all_2019_2020.csv')\n",
    "df_all_2019_2020 = pd.read_csv(file, parse_dates=True, infer_datetime_format=True)\n",
    "df_all_2019_2020 = df_all_2019_2020.loc[df_all_2019_2020['date'] >= '2010-09-01']\n",
    "df_all_2019_2020 = df_all_2019_2020.round(decimals=2)\n",
    "df_all_2019_2020['date'] = pd.to_datetime(df_all_2019_2020['date']).apply(datetime.toordinal)\n",
    "df_all_2019_2020['price'] = df_all_2019_2020.astype('int')\n",
    "df_all_2019_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                   int64\n",
       "price                  int32\n",
       "uup                  float64\n",
       "gdp                  float64\n",
       "prod                 float64\n",
       "vader                float64\n",
       "textblob_polarity    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2019_2020.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "# X, y = make_classification(n_samples = 1000, n_features = 30, n_informative = 5,\n",
    "#                            n_redundant = 15, n_repeated = 5, \n",
    "#                            n_clusters_per_class = 2, class_sep = 0.5,\n",
    "#                            random_state = 1000, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "# Numpy array to pandas dataframe\n",
    "# labels = ['date', 'uup', 'gdp', 'prod', 'vader', 'textblob_polarity']\n",
    "X = df_all_2019_2020.drop(columns = 'price')\n",
    "y = df_all_2019_2020[\"price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,\n",
    "                                                    random_state = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of tuples with classifier label and classifier object\n",
    "classifiers = {}\n",
    "classifiers.update({\"LDA\": LinearDiscriminantAnalysis()})\n",
    "classifiers.update({\"QDA\": QuadraticDiscriminantAnalysis()})\n",
    "classifiers.update({\"AdaBoost\": AdaBoostClassifier()})\n",
    "classifiers.update({\"Bagging\": BaggingClassifier()})\n",
    "classifiers.update({\"Extra Trees Ensemble\": ExtraTreesClassifier()})\n",
    "classifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})\n",
    "classifiers.update({\"Random Forest\": RandomForestClassifier()})\n",
    "classifiers.update({\"Ridge\": RidgeClassifier()})\n",
    "classifiers.update({\"SGD\": SGDClassifier()})\n",
    "classifiers.update({\"BNB\": BernoulliNB()})\n",
    "classifiers.update({\"GNB\": GaussianNB()})\n",
    "classifiers.update({\"KNN\": KNeighborsClassifier()})\n",
    "classifiers.update({\"MLP\": MLPClassifier()})\n",
    "classifiers.update({\"LSVC\": LinearSVC()})\n",
    "classifiers.update({\"NuSVC\": NuSVC()})\n",
    "classifiers.update({\"SVC\": SVC()})\n",
    "classifiers.update({\"DTC\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ETC\": ExtraTreeClassifier()})\n",
    "\n",
    "# Create dict of decision function labels\n",
    "DECISION_FUNCTIONS = {\"Ridge\", \"SGD\", \"LSVC\", \"NuSVC\", \"SVC\"}\n",
    "\n",
    "# Create dict for classifiers with feature_importances_ attribute\n",
    "FEATURE_IMPORTANCE = {\"Gradient Boosting\", \"Extra Trees Ensemble\", \"Random Forest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "# Initiate parameter grid\n",
    "parameters = {}\n",
    "\n",
    "# Update dict with LDA\n",
    "parameters.update({\"LDA\": {\"classifier__solver\": [\"eigen\"], \n",
    "                                         }})    # switch from svd solver to eigen\n",
    "\n",
    "# Update dict with QDA\n",
    "parameters.update({\"QDA\": {\"classifier__reg_param\":[0.01*ii for ii in range(0, 101)], \n",
    "                                         }})  # this regs the per-class covariance estimates by transfroming S2 where\n",
    "                                              # S2 corresponds to the scaling attribute of a given class\n",
    "# Update dict with AdaBoost\n",
    "parameters.update({\"AdaBoost\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 1.0]\n",
    "                                 }})\n",
    "\n",
    "# Update dict with Bagging\n",
    "parameters.update({\"Bagging\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__max_features\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                \"classifier__n_jobs\": [-1] # using all processors, 1 none running in parallel\n",
    "                                }})\n",
    "\n",
    "# Update dict with Gradient Boosting\n",
    "parameters.update({\"Gradient Boosting\": { \n",
    "                                        \"classifier__learning_rate\":[0.15,0.1,0.05,0.01,0.005,0.001], \n",
    "                                        \"classifier__n_estimators\": [200],\n",
    "                                        \"classifier__max_depth\": [2,3,4,5,6],\n",
    "                                        \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"classifier__subsample\": [0.8, 0.9, 1]\n",
    "                                         }})\n",
    "\n",
    "\n",
    "# Update dict with Extra Trees\n",
    "parameters.update({\"Extra Trees Ensemble\": { \n",
    "                                            \"classifier__n_estimators\": [200],\n",
    "                                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                            \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                            \"classifier__n_jobs\": [-1]\n",
    "                                             }})\n",
    "\n",
    "\n",
    "# Update dict with Random Forest Parameters\n",
    "parameters.update({\"Random Forest\": { \n",
    "                                    \"classifier__n_estimators\": [200],\n",
    "                                    \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                    \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                    \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                    \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                    \"classifier__n_jobs\": [-1]\n",
    "                                     }})\n",
    "\n",
    "# Update dict with Ridge\n",
    "parameters.update({\"Ridge\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with SGD Classifier\n",
    "parameters.update({\"SGD\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0],\n",
    "                            \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with BernoulliNB Classifier\n",
    "parameters.update({\"BNB\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with GaussianNB Classifier\n",
    "parameters.update({\"GNB\": { \n",
    "                            \"classifier__var_smoothing\": [1e-9, 1e-8,1e-7, 1e-6, 1e-5]\n",
    "                             }})\n",
    "\n",
    "# Update dict with K Nearest Neighbors Classifier\n",
    "parameters.update({\"KNN\": { \n",
    "                            \"classifier__n_neighbors\": list(range(1,31)),\n",
    "                            \"classifier__p\": [1, 2, 3, 4, 5],\n",
    "                            \"classifier__leaf_size\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "# Update dict with MLPClassifier\n",
    "parameters.update({\"MLP\": { \n",
    "                            \"classifier__hidden_layer_sizes\": [(5), (10), (5,5), (10,10), (5,5,5), (10,10,10)],\n",
    "                            \"classifier__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                            \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                            \"classifier__max_iter\": [100, 200, 300, 500, 1000, 2000],\n",
    "                            \"classifier__alpha\": list(10.0 ** -np.arange(1, 10)),\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"LSVC\": { \n",
    "                            \"classifier__penalty\": [\"l2\"],\n",
    "                            \"classifier__C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"NuSVC\": { \n",
    "                            \"classifier__nu\": [0.25, 0.50, 0.75],\n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__degree\": [1,2,3,4,5,6],\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"SVC\": { \n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__gamma\": [\"auto\"],\n",
    "                            \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                            \"classifier__degree\": [1, 2, 3, 4, 5, 6]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with Decision Tree Classifier\n",
    "parameters.update({\"DTC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n",
    "# Update dict with Extra Tree Classifier\n",
    "parameters.update({\"ETC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAFcCAYAAACa3zafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAumUlEQVR4nO3de1xUdf4/8NdhBhE0RF3AQvOrUV+zIPXrKpILggZpAgKud8H7FUjXzFVcrYhYU9dM9oFiPbzkZclEUEvARFvLEHV/wn4VctstFURAuYmiInN+f/jl5KgwM40z58zM69ljHnHOMDMvfeCbz+18jiCKoggiIvrV7OQOQERk6VhIiYiMxEJKRGQkFlIiIiOxkBIRGYmFlIjISCykRGRz6uvrMXLkSJSUlDzyXFFRESIiIhAcHIz4+Hjcu3dP5/uxkBKRTSkoKMD48ePx888/P/b5xYsXY8WKFcjOzoYoivj88891vicLKRHZlM8//xwrV66Em5vbI8+Vlpbi9u3b6NOnDwAgIiICWVlZOt9T/aRDEhGZW11dHerq6h457+zsDGdnZ61ziYmJLb5PRUUFXF1dpWNXV1eUl5fr/HyzFlLHZ8eb8+MM0rXXMLkjtCr/gLvcEVr1vPfXckdoVdZ3r8kdoVU9n2qSO0KrOjmEmvXzDK0VHy72RXJy8iPnY2JiEBsbq/f7aDQaCIIgHYuiqHXcErZIiUhxBMGwUcfo6GiEh4c/cv7h1qguXbp0QWVlpXR87dq1xw4BPIyFlIgURzBw+uZxXfhfw8PDAw4ODjhz5gz+53/+B5mZmfDz89P5Ok42EZHiCIKdQQ9jzZw5E//85z8BAGvWrEFSUhJef/113Lp1C1FRUTpfzxYpESnOkyiOuuTm5kpfb968Wfq6V69e+OKLLwx6LxZSIlIcfSZ4lISFlIgUyLJGHVlIiUhxzNG1f5JYSIlIcVhIiYiMZOjyJ7mxkBKR4rBFSkRkJDs7yypNlpWWiGyCAC5/IiIyCrv2RERGYiElIjISCykRkdFYSImIjMIWKRGRkSytkOqVtrS0FFOnTkVQUBAqKioQFRX12NuYEhE9CQLsDHrITa8EK1aswPTp09GuXTu4urpi5MiRWLJkiamzEZGNMvfGzsbSK0F1dTUGDx4s3QhqzJgxqK+vN3U2IrJRgiAY9JCbXmOkbdu2xdWrV6XAp0+fRps2bUwajIhslxJamYbQq5D+8Y9/xOzZs3Hp0iWEhYWhtrYW69evN3U2IrJRShj3NIRehbR79+744osv8PPPP6OpqQk9e/bUumUpEdGTZGkt0lbTlpWV4cqVK5g4cSKuXbuGdu3awdnZGeXl5Zg+fbq5MhKRjbET1AY95NZqgo8//hgnT55ERUUFJk6c+MuL1GoMGTLE1NmIyFZZWIu01UKalJQEAEhNTcWsWbPMEoiIyNK69nq1iSMjI7F161bcvHkToihCo9GgpKQEH374oanzEZENUsKSJkPoVfYXLlyIoqIi7N+/Hw0NDcjOzoadnWX9xiAiy2GVVzZVVFRg1apVCAwMRFBQEHbs2IHz58+bOhsR2SirvLKpQ4cOAIAePXqguLgYHTt2hCiKJg1GRDZMEAx7yEyvMVIfHx/ExcVhyZIlmDZtGs6dOwcnJydTZyMiWyV/I9MgrRbSjIwMAPdbot26dcOpU6cwbtw4CIIADw8Pc+QjIlukgFamIVotpCdPngQAXL58GRcvXoSfnx9UKhW+/fZbeHp6miUgEdkgayqkzetIJ0+ejMzMTHTq1AkAUFtbi/nz55s+HRHZJmvq2jerqKiAi4uLdOzo6Mhr7YnIZERrapE2GzJkiLRDviiKOHToEIYPH27qbERkqyyrjupXSJcuXYrs7Gzk5+dDEARMmzYNQ4cONXU2IrJVdpZVSfXeNiU4OBjBwcFGfVjXXsOMer0plRR/LXeEVtkJU+SO0CqXF/rIHaFVjiplr3u+p+x45meNXXsiIrNSsZASERmHLVIiIiNZVh1lISUiBbLWySYiIrOxrDrKQkpEymNpC/It7EIsIrIJdoJhDwMcOHAAI0aMQFBQEHbu3PnI8+fOnUNkZCRCQ0Mxe/Zs1NXV6Y5rUAIiInMQDHzoqby8HOvWrcOuXbuQkZGBtLQ0/Pjjj1rfk5iYiLi4OOzfvx89evTAp59+qvN92bUnIuUxsGtfV1f32Jajs7MznJ2dpeMTJ07Ax8dH2jskODgYWVlZiImJkb5Ho9Hg5s2bAICGhgZpY/vWsJASkfIY2F3ftm0bkpOTHzkfExOD2NhY6biiogKurq7SsZubGwoLC7Ve88c//hHTpk3DBx98AEdHR3z++ec6P5+FlIiUx8C5pujoaISHhz9y/sHWKHC/tfngHUpFUdQ6vn37NuLj47F161Z4e3tjy5YtWLJkCVJTU1v9fBZSIlIeA7v2D3fhW9KlSxecPn1aOq6srISbm5t0fOHCBTg4OMDb2xsAMHbsWKxfv17n+3KyiYiUx0Q3v/P19cX333+PqqoqNDQ0ICcnB35+ftLz3bt3x9WrV/Gf//wHAHDkyBF4eXnpfF+2SIlIeUzUxHN3d8fChQsRFRWFxsZGjB49Gt7e3pg5cybi4uLg5eWFpKQkLFiwAKIoonPnzvjggw90vi8LKREpjwkX5IeEhCAkJETr3ObNm6Wv/f394e/vb9B7spASkeKI3EaPiMhIFnaJKAspESmPZdVRFlIiUiAL20ZPr7mxK1euYO7cuejbty8GDBiARYsWoaqqytTZiMhWmWj5k6noVUjfeustvPrqqzh+/Li0rmrJkiWmzkZEtspEm5aYil6FtL6+HpMmTUL79u3x1FNPYcqUKSgvLzd1NiKyVSbcRs8kcfX5pr59+yIzM1M6PnbsGHr37m2yUERk4yyskOo12XT48GGkpaVh5cqVEAQBDQ0NAICMjAwIgoCioiKThiQi2yLKXxsNolchPXHihKlzEBH9QgGtTEPoVUgft88fAK3NUImInhgFzMQbwuCtARobG5Gbm4vr16+bIg8RkXWOkT7c8pw/fz6mTZtmkkBERJa2weevurLp5s2buHLlypPOQkR0n4V17fUqpIGBgdJ2/KIoora2FjNmzDBpMCKyYQrorhtCr0L64M2jSktL9d7Wn4jo17DKbfTy8/OlrxsbG3HmzBn0798fo0aNMlUuIrJl1tgiTUpK0jquqanBwoULTRKIiMgqx0gf5uTkhNLS0iedhYjoPmtskU6ePFlrsqmkpMTge5oQEenNsuqo4ZNNgiCgY8eO8PT0NFkoIrJtojW2SAcMGGDqHEREv7DGQkpEZFa2MNlERGRStnCJ6K+Vf8DdnB9nEDthitwRWtXFc6vcEVr1+bdRckdo1Ysuz8odoVV2gr3cEZSFLVIiIiNxjJSIyEgspERExhHZtSciMhInm4iIjKSyrErKQkpEysMxUiIiI1lWHWUhJSLlscpr7YmIzIqz9kRERmKLlIjISJZVR1lIiUh57Cxr9RMLKREpj4UNkbKQEpHysJASERlJsLBKamEjEURkCwTBsIchDhw4gBEjRiAoKAg7d+585Pn//Oc/mDx5MkJDQzF9+nTU1tbqfE8WUiJSHFMV0vLycqxbtw67du1CRkYG0tLS8OOPP0rPi6KIuXPnYubMmdi/fz9efPFFpKam6nxfFlIiUhzBzrCHvk6cOAEfHx+4uLjAyckJwcHByMrKkp4/d+4cnJyc4OfnBwCYM2cOJk6cqPN99RojvXLlChISEpCXlwd7e3v87ne/Q3x8PDp16qT/n4CISE+Gdtfr6upQV1f3yHlnZ2c4OztLxxUVFXB1dZWO3dzcUFhYKB1funQJv/nNb7Bs2TIUFRWhZ8+e+NOf/qTz8/Wq5W+99RZeffVVHD9+HEeOHIGXlxeWLFmiz0uJiAymsjPssW3bNgwdOvSRx7Zt27TeV6PRaE1kiaKodXzv3j3k5+dj/Pjx2LdvH7p164Y///nPOvPq1SKtr6/HpEmTpOMpU6YgPT1dn5cSERnM0BZpdHQ0wsPDHzn/YGsUALp06YLTp09Lx5WVlXBzc5OOXV1d0b17d3h5eQEARo4cibi4OJ2fr1eLtG/fvsjMzJSOjx07ht69e+vzUiIigwmCYNDD2dkZXbt2feTxcCH19fXF999/j6qqKjQ0NCAnJ0caDwXu17qqqioUFxcDAHJzc/HSSy/pzKtXi/Tw4cNIS0vDypUrIQgCGhoaAAAZGRkQBAFFRUV6/wUREeliyASSIdzd3bFw4UJERUWhsbERo0ePhre3N2bOnIm4uDh4eXnhr3/9K5YvX46GhgZ06dIFH374oe68oiiKpon8qOo7B831UQZT+n3FeV9747zRjfe1N84LZv0078+OG/T9hZN/Z6Ik+mm1RZqcnNzqi2NiYp5oGCIiwPIuEdWrAV1YWIicnBzY2dmhTZs2+Oabb7QWsRIRPUmmvLLJFFptkTa3OMeNG4e0tDQ4OjoCuD9DFhWl7K4cEVkuC9vXWb/Jpurqaq21Vo2NjaipqTFVJiKycUpoZRpCr0I6ZswYREZGws/PD6Io4ujRo4iOjjZ1NiKyUVZZSDt16oTIyEipVRoaGopOnTrhwoULeOEF887mEZH1Eyysb69XIc3NzUVRURGGDRsGURRx7NgxuLm54datWwgJCcGUKVNMHJOIbIlVtkgrKyuRnp4uXSUQGxuLOXPmIC0tDRERESykRPREWWUhra6uRrt27aRjBwcH1NbWQq1WW9xO1kSkfJZWVvQqpEFBQYiOjsbw4cOh0WiQk5ODoUOHIiMjQ2tLKiKiJ8HChkj1K6SLFi3C0aNH8d1330GlUmHGjBnw9/fH2bNnsXbtWlNnJCIbY6eSO4Fh9L75XUBAAAICArTO9enT50nnISKyzq49EZE5WdrcCwspESmOhdVRFlIiUh4W0lY87/21OT/OIC4v9JE7QquUvt/nmMHb5Y7QqpNndd8JUk5d25ltW+BfpZODea9gZCElIjKSVS5/IiIyJxZSIiIj2QnKHup4GAspESkOW6REREYy0U1ETYaFlIgUh117IiIjsWtPRGQkdu2JiIyksmPXnojIKOzaExEZiV17IiIjcdaeiMhI7NoTERmJXXsiIiOxRUpEZCSOkRIRGYktUiIiI1nVGGlGRkarLx41atQTjEJEdJ9Vde1PnjwJALh06RIuXrwIf39/qFQqfPvtt/D09GQhJSKTsKqufVJSEgBg8uTJ2L9/Pzp16gQAqK2txfz5802fjohsklUV0mYVFRVwcXGRjh0dHVFZWWmqTERk46xqjLTZkCFDMHXqVAQFBUEURRw6dAjDhw83dTYislFWNUbabOnSpcjOzkZ+fj4EQcC0adMwdOhQU2cjIhultsauPQC0bdsW9vb2aGpqgiha1m8LIrIsljZGqtdQxObNm5GcnIxnnnkGXbt2xcaNG5GSkmLqbERkowRBNOhhiAMHDmDEiBEICgrCzp07W/y+Y8eOITAwUK/31KtFun//fuzZswdt27YFAIwZMwYRERGYO3euXh9CRGQIU7VIy8vLsW7dOqSnp6NNmzYYN24cBg4cCE9PT63vu3btGlatWqX3++rVIhVFUSqiAODg4AC1mhdFEZFp2Bn4qKurQ0lJySOPuro6rfc9ceIEfHx84OLiAicnJwQHByMrK+uRz1++fDliYmL0zqtXNfTx8UFsbCzCw8MB3L/iaeDAgXp/CBGRIQydtd+2bRuSk5MfOR8TE4PY2FjpuKKiAq6urtKxm5sbCgsLtV6zfft29O7dG6+88oren69XIY2Pj8fu3buRkZEBURTh4+ODsWPH6v0hRESGMLRrHx0dLTX0HuTs7Kx1rNFoIAi/vLkoilrHFy5cQE5ODrZu3YqrV6/q/fl6FdIZM2bg008/xYQJE/R+YyKiX8vQQurs7PxI0XycLl264PTp09JxZWUl3NzcpOOsrCxUVlYiMjISjY2NqKiowIQJE7Br167W8+oTsqGhAWVlZfp8KxGR0VQGPvTl6+uL77//HlVVVWhoaEBOTg78/Pyk5+Pi4pCdnY3MzEykpqbCzc1NZxEF9GyRVlVVITAwEJ07d4aDg4N0/siRIwb8EYiI9GOqK5vc3d2xcOFCREVFobGxEaNHj4a3tzdmzpyJuLg4eHl5/ar31auQpqSk4JtvvkFeXh5UKhX8/f0xaNCgX/WBRES6mHJBfkhICEJCQrTObd68+ZHv69q1K3Jzc/V6T70K6caNG3Hnzh2MGTMGGo0GmZmZ+Ne//oX4+Hi9PoSIyBCWdmWTXoW0oKBAa61VYGAgRo4cabJQRGTbVBZWSPWabOratSsuXrwoHV+7dg3u7u4mC0VEts1OMOwhN71apPfu3UNYWBj69+8PtVqNM2fOwNXVFVFRUQDuL2AlInpSrHIbvXnz5mkdT5s2zSRhiIgAwF4BrUxD6FVIBwwY8EQ+LOu7157I+5iCo0rZvwFfdHlW7gitOnl2otwRWjWwT8u7/ChB34+UfeueExHm/TwldNcNwZ1HiEhxrLJrT0RkTpY2a89CSkSKw649EZGRWEiJiIzEQkpEZCQVJ5uIiIyj1yWXCsJCSkSKw649EZGRWEiJiIzEMVIiIiOxRUpEZCQWUiIiI7GQEhEZyd6OY6REREbhOlIiIiOxa09EZCRuo0dEZCRL29hZ51DEunXrzJGDiEhiaXcR1VlIjx49ClG0rN8ORGTZLK2Q6uzau7i44PXXX8dLL70EBwcH6XxSUpJJgxGR7bK6Wfvw8HBz5CAikggKaGUaQq9CWlJSgh9//BGDBw9GWVkZunXrZo5sRGSjLKyO6m5Bf/XVV5g7dy4SExNRW1uLcePGITMz0xzZiMhGCYJhD7npLKSbN2/G7t270a5dO3Tu3Bn79u1DamqqObIRkY2yM/AhN51dezs7O7Rv3146dnNzg52dEqITkbUSLGwdqc5C+vzzz2PHjh24d+8eioqKsGvXLvTq1csc2YjIRimgt24QnU3LFStWoLy8HA4ODli2bBnat2+PlStXmiMbEdkoq1tH6uTkhEWLFmHRokXmyENEpIjiaIgWC2mvXr0gPDAdplaroVKpcOfOHbRv3x6nTp0yS0Aisj0WVkdbLqTFxcUAgJUrV6Jfv34IDQ2FIAjIzs7G8ePHzRaQiGyPEpY0GULnGGlhYSHCwsKk1mlwcDD+93//1+TBiMh2CQY+5KazkDo6OmLv3r24desW6uvrsXPnTnTo0MEc2YjIRlldIV29ejUOHz6MV199FX5+fsjLy8OHH35ojmxEZKOsbtbew8MDGzdu1Dp3+/ZtkwUiIjJlbTxw4ABSUlJw7949REdHY+LEiVrPf/3119iwYQNEUUTXrl2RlJSksxeus5Dm5ubio48+wq1btyCKIjQaDRoaGpCXl2fcn4aIqAWmurKpvLwc69atQ3p6Otq0aYNx48Zh4MCB8PT0BADU19fjnXfewd69e+Hu7o7169djw4YNWL58eavvq7Nrn5SUhGXLluG5557DmjVrMGLECIwYMeLJ/KmIiB7DVGOkJ06cgI+PD1xcXODk5ITg4GBkZWVJzzc2NmLlypVwd3cHAPz3f/83ysrKdL6vzhbpU089BR8fH/zjH//AjRs3sHjxYhZSIjIpQ5c/1dXVoa6u7pHzzs7OcHZ2lo4rKirg6uoqHbu5uaGwsFA67tixI1577TUA94cwU1NTMXnyZJ2fr7OQtm3bFj/99BOee+455Ofnw8fHB42NjTrfmIjo1zJ0W6Rt27YhOTn5kfMxMTGIjY2VjjUajdaFRqIoah03u3HjBubPn49evXrptbm9zkK6cOFCfPTRR1i9ejVSU1ORlpaG0aNH63zjx+n5VNOvep053FP4ZjN2gr3cEVrVtZ2y/wL7fjRf7git+n8L/ip3hNZFDDbrxxnaIo2Ojn5swXuwNQoAXbp0wenTp6XjyspKuLm5aX1PRUUFpk+fDh8fHyxbtkyvz9dZSJOSknD37l1s3boVycnJcHJy4jpSIjIpQ2ftH+7Ct8TX1xcbNmxAVVUVHB0dkZOTg4SEBOn5pqYmzJkzB8OHD8e8efP0/nydhTQ9PR0XL17EwYMHMWvWLLi4uCAsLOxXt0qJiHQx1SWi7u7uWLhwIaKiotDY2IjRo0fD29sbM2fORFxcHK5evYrz58+jqakJ2dnZAICXX34ZiYmJrecV9bzX8q1bt3DkyBFs2bIF9fX1yMnJMfgPUXVnv8GvMReld+3d2ip7D9iqOz/IHaFVI7/sKHeEVim9a99wabdZP+/KrQMGff8zTiEmSqIfnS3Sw4cP48CBAygoKEBAQACWL1+Ofv36mSMbEdkoBVysZBCdhXT//v0ICwvD2rVrYW+v7AkPIrIOVnerkQ0bNpgjBxGRxOpapERE5mZp+5GykBKR4lhYHWUhJSLlsbQbvrOQEpHisGtPRGQ0y6qkLKREpDgCCykRkXEEwbJGSVlIiUiB2CIlIjIKu/ZEREZjISUiMgrHSImIjCRY2JJ8nWnfffddrZtDERGZmmDgf3LT2SL19vbG2rVrUVVVhbCwMISFhWndhY+I6MmzrBapzkIaHh6O8PBwlJWV4eDBgxg3bhw8PT3x+9//HsOGDTNHRiKyMY+7s6eS6VX2L1++jPT0dOzbtw/du3fHa6+9hkOHDuHtt982dT4iskmCgQ956WyRjh8/HteuXcOoUaPwySef4JlnngEAjBo1Cn5+fiYPSES2RwnjnobQWUinTp2KoKAgrXOlpaXw8PDAiRMnTBaMiGyZlYyRlpWVQRRFfPzxx/Dy8kLzzUabmpowc+ZMZGVlmS0kEdkWq2mRfvzxxzh58iQqKiowceLEX16gVmPIkCHmyEZENsrSJptaLKRJSUkAgNTUVMyaNctsgYiIlDCBZIgWC2laWhrGjh2Lu3fvIjk5+ZHnY2JiTBqMiGyXpV3Z1GIhbR4TJSIyPytpkY4bNw7A/Rn65m4+EZE5WNoYqc7284ULF3Dz5k1zZCEi+j9WtiDfzs4OAQEB6NGjBxwcHKTz27dvN2kwIrJdAlRyRzCIzkK6ePFic+QgIpJY2jpSnV37AQMGoH379rCzs4MgCNBoNLh06ZI5shGRjRIEwaCH3HS2SJcvX478/HzU1taiZ8+eKC4uRr9+/TB69Ghz5CMim2RZy590pj1x4gS+/PJLBAcHIyEhAdu3b8ft27fNkY2IbJSlbeyss5C6ubnB3t4ezz33HH744Qd4eXnhxo0b5shGRDbLymbt3d3dsWnTJgwaNAirV68GANy9e9fkwYjIdilh3NMQOlukiYmJ6Nq1K7y9vREUFISDBw/inXfeMUM0IrJddgY+5CWILVwLeuXKlVZf2LzBMxGRrWuxkAYGBkIQhMdecy8IAo4cOWLycERElqDFQkpERPrRObhQVVWFBQsWYODAgejfvz9iYmJw7do1c2QjIrIIOgvpihUr4OXlhSNHjiA3NxevvPIK4uPjzZGNiMgi6Cykly9fxvTp09G+fXs4Oztj5syZOieiiIhsic5CKggCysrKpOMrV65Arda5/JSIyGborIhvvvkmxo4di1deeQWiKKKgoAAJCQnmyEZEZBH0mrWvqqpCYWEhRFGEt7c3OnfubI5sREQWQWeLtK6uDikpKcjLy4NarYafnx/mzp2Ltm3bmiMfEZHi6WyRzp49Gz179sSoUaMgiiL27t2LqqoqrF271lwZiYgUTWchHTlyJA4ePKjzHBGRrdI5a+/p6YnTp09Lx8XFxejevbtJQxEp0bp16+SO0Kp3330XhYWFcsewSTpbpKGhobhw4QJ69OgBlUqFn376CR06dEDbtm3Nfs19aWkpli9fjtLSUuzYsQNvvfUWPvjgA3Tt2tVsGVpz5coVJCQkIC8vD/b29vjd736H+Ph4dOrUSe5oAJSbLyMjo9XnR40aZZYcuoSGhiIzM1OxW7zt27cPGRkZqKqqQlhYGMLCwuDq6ip3LJugs5CWlpa2+Fx1dTVefvnlJx6qJdOnT8fUqVOxdu1apKenY8+ePcjMzMTOnTvNlqE1EyZMwIgRI7TGk7/77jts3rxZ7mgAlJtv6dKlAIBLly7h4sWL8Pf3h0qlwrfffgtPT0+kpqbKmq9ZVFQUysvL8dJLL2ndUTcpKUnGVI8qKyvDwYMH8be//Q2enp74/e9/j2HDhskdy6rpnLX38PBo8bmYmBjs27fviQZqTXV1NQYPHow1a9ZAEASMGTNGMUUUAOrr6zFp0iTpeMqUKUhPT5cxkTal5msuRJMnT8b+/fulFnJtbS3mz58vZzQt4eHhckfQ6fLly9i/fz++/PJLdO/eHa+99hoOHTqEnJwcfPjhh3LHs1pGXaJk7o2j2rZti6tXr0pdq9OnT6NNmzZmzdCavn37IjMzE2FhYQCAY8eOoXfv3jKn+oXS81VUVMDFxUU6dnR0RGVlpXyBHhIeHo6SkhL8+OOPGDx4MMrKytCtWze5Y0nGjx+Pa9euYdSoUfjkk0+kPYNHjRoFPz8/mdNZN6O20QsPDzdri7SwsBB/+tOfcOnSJTz77LOora3F+vXr8corr5gtQ2t8fX1RVVUljR83NDRIzwmCgKKiIhnTKT9fUlISiouLERQUBFEUcejQIfz2t7/FggULZM3V7KuvvkJKSgpu376Nv/3tbwgNDcXbb78t/WKSW05ODoKCgrTOlZaWttqrpCfDogppbW0tnJyc8PPPP6OpqQk9e/ZEZWUlf1CsSHZ2NvLz8yEIAgYNGoShQ4fKHUkSHh6Ozz77DJMmTUJGRgYqKiowdepUfPnll7LmKisrgyiKmDVrFjZv3iz1FJuamjBz5kxkZWXJms8WWMTuIw//oLRr1w4AUF5erqgflOTk5Meej4mJMXMSbS3laiZ3vge1bdsW9vb2aGpqMvvQkS52dnZo3769dOzm5gY7O/nvF/Txxx/j5MmTqKiowMSJE6XzarUaQ4YMkS+YDbGIMVJL/EFpbGzE8ePHFTPsANwfGrl69Spef/11qNVqHD58WFGt+c2bNyMnJwchISEQRREbN27Ev/71L8ydO1fuaACA559/Hjt27MC9e/dQVFSEXbt2oVevXnLHkibrUlNTMWvWLJnT2Ca9uvbFxcU4deoU1Go1Bg4ciJ49ewK4P0NozsF2S/tBuXv3LqZNm4YdO3bIHQUAMG7cOGzZsgWOjo4AgDt37iAqKgppaWkyJ7svJCQEe/bskfZxaGhoQEREBA4dOiRzsvtu3bqFlJQUnDhxAhqNBj4+Ppg/f75WK1UOaWlpGDt2rGJ7RLZAZ4t0+/bt2LlzJwICAqDRaLB161bMmTMH4eHhZp+xjIyMxNatW3Hz5k2IogiNRoOSkhLFLuu4efOmojbBrq6u1lpM3tjYiJqaGvkCPUQURa3NcBwcHBS1962TkxMWLVqERYsWyR1Fi9KGQGyRzp/SPXv2YO/evdJv3fnz52PSpEmyrKlbuHAhnn76aZw9exbDhg3DsWPH4OXlZfYcLWm+8ypw/4e7trYWM2bMkDnVL8aMGYPIyEj4+flBFEUcPXoU0dHRcseS+Pj4IDY2VvrZysjIwMCBA2VOBfTq1UvrF5BarYZKpcKdO3fQvn17nDp1SsZ093sawP0ZeqVdHGArdBZSR0dH2Nvbax3LtXazoqIC27dvx6pVqxAUFIQZM2YoqhDExsZKX5eWlsLZ2RnOzs4yJtLWqVMnREZGSkUhNDQUnTp1woULF/DCCy/InA6Ij4/H7t27kZGRAVEU4ePjg7Fjx8odC8XFxQCAlStXol+/fggNDYUgCMjOzsbx48dlTveLCxcu4ObNm9JkLJlPi4W0ebzFxcUF48ePx4gRI6BWq5GVlYX/+q//Mlc+LR06dAAA9OjRA8XFxdKu/UqRn58vfd3Y2IgzZ86gf//+irlWPDc3F0VFRRg2bBhEUcSxY8fg5uaGW7duISQkBFOmTJE134wZM/Dpp59iwoQJsuZoSWFhId59913pODg4GCkpKTIm0mZnZ4eAgAD06NFD6xLW7du3y5jKNuhskXp7ewMAbt++DQAYPHiwaRO1wsfHB3FxcViyZAmmTZuGc+fOwcnJSbY8D3u4W1VTU4OFCxfKlOZRlZWVSE9Pl1rJsbGxmDNnDtLS0hARESF7IW1oaEBZWRmefvppWXO0xNHREXv37sXw4cOh0WiQmZkp/XJXgsWLF8sdwWa1WEgfnOmrqqpCQUEBmpqa0KdPH/zmN78xS7hmzbsD9ejRA926dcOpU6cwbtw4CIKgqOU7D3Nycmp10xdzq66u1ur2OTg4oLa2Fmq1WhE7GlVVVSEwMBCdO3fWalGZc4ex1qxevRoJCQl4//33IQgCXn31VUVNdA4YMADnz5/HrVu3IIoimpqaUFJSggEDBsgdzerpbJEeP34cy5YtQ58+faDRaLBixQokJiYiICDAHPkAACdPngRwf7nVxYsX4efnp7U7kFJMnjxZa7KppKQE/v7+Mqf6RVBQEKKjo6UWVU5ODoYOHYqMjAxFbLeWkpKCb775Bnl5eVCpVPD398egQYPkjiXx8PDAxo0btc4199SUYPny5cjPz0dtbS169uyJ4uJi9OvXD6NHj5Y7mtXTuY40IiIC69evl5Y6Xb58GTExMcjMzDRLwAdNnjwZ69evf2R3IKWs03xwjFQQBHTs2FFRhR4Ajh49iu+++w4qlQq+vr7w9/fH2bNn0aNHD9m7qUuWLMGdO3cQGhoqdZ27dOmC+Ph4WXM1y83NxUcffSS1+DQaDRoaGpCXlyd3NAD3V41kZ2cjISEBUVFRaGhowJ///GdF7ZBmrXS2SO/du6e1XrRbt27QaDQmDdUSpe8OZAldqICAgEd6E3369JEnzEMKCgq0LvcNDAzEyJEjZUykLSkpCQkJCdiyZQvmzJmDr7/+WmvjF7m5ubnB3t4ezz33HH744Qe88cYbuHHjhtyxbILOQvrMM89g69atUvfgiy++kG1ccsiQIZg6darW7kDDhw+XJQs9eV27dsXFixelW9lcu3YN7u7uMqf6xVNPPQUfHx/84x//wI0bN7B48WKMGDFC7lgSd3d3bNq0CYMGDcLq1asB3L+6jkxPZ9f++vXr0u0pmtf2xcfHw83NzVwZtSh5dyAyzpQpU3D27Fn0798farUaZ86cgaurqzS5KfcyngkTJiAxMREXLlzAP//5T8TFxeGNN97A4cOHZc3VrL6+Ht988w3eeOMNfPbZZzhx4gSio6Ph4+MjdzSrZ9Q2ekRP0oNjzI8j99DJqVOnsGPHDqxevRrjx4/HpUuXMHr0aCxZskTWXLouQ27e4JlMp8VC+uDljo+jlCUpROYSERGBu3fvIjQ0FCEhIXBycpJ9gg745d/q4/4pm/sGlbaqxUKqa/2jktdvEpnKxYsXcfDgQWRlZcHFxQVhYWFcXkT6de1zc3ORn58PtVoNX19f+Pr6miMbkSLdunULR44cwZYtW1BfX4+cnBy5IwG4f0HDe++9h++//x5NTU3w8fHBO++8Y/YLaGyRzkK6du1anDlzRlrE/dVXXyEwMBCzZ882V0YiRTh8+DAOHDiAgoICBAQEIDQ0FP369ZM7liQmJgZ9+/bF2LFjodFokJaWhtOnT2PTpk1yR7N6OgtpSEgI0tPTpR2g7ty5g8jISBw8eNAsAYmUIjY2FmFhYfD399faEU0pwsLCHrlQJiQkBAcOHJApke3QuY60Q4cOuHnzprQQvrGxUfYdwYnksGHDBrkjtEoQBK1NX65cuaKojbGtWYt/y0uXLgUAaDQahIWFITAwECqVCn//+9+lW40QkXK8+eabGDt2rLS9ZEFBARISEuSOZRNa7Nq3dptlQRAUs8cmEf2iqqoKhYWFEEUR3t7e6Ny5s9yRbEKLLdLm2z1s2rTpkYmlv/zlL6ZNRUQGq6urQ0pKCvLy8qBWq+Hn54e5c+dq3QeLTKPFFumaNWtw/fp15ObmIjAwUDrf1NSEgoICZGdnmy0kEek2e/Zs9OzZE6NGjYIoiti7dy+qqqqwdu1auaNZvRZbpEFBQfj3v/+NvLw8rUvzVCoV5s2bZ5ZwRKS/0tJSraVO8fHxito9y5q1WEi9vb3h7e2NF198Eb169dJ6Ts77NhHR43l6euL06dPo378/gPs37WveSYtMS+c60sDAQEyYMAEzZsxATU0N3nnnHVy8eLHVySgiMr/Q0FBcuHABPXr0gEqlwk8//YQOHTqgbdu2vObexHQW0pqaGrz//vsoKSnB9evXMWHCBERFRUGlUpkrIxHpobX9Maqrq/Hyyy+bMY1t0blaVxRF2Nvbo6GhAaIoQhAE2NnZmSMbERmgtY2EYmJi2Is0IZ0VMSQkBB4eHti7dy/27NmDs2fPcrcbIgvDbYdNS2eLNDU1Fb179wYAdOzYER999BEOHTpk8mBE9OQo4Xbb1kxni9TT0xMpKSl4++23UV9fj+TkZN7eg4joAToL6XvvvYeGhgacP38eKpUKly5dUsztcYmIlEBnIT137hz+8Ic/QK1Ww9HREatWrUJRUZE5shHRE8IxUtPSOUYqCALu3r0rjbFUV1dzvIVIoYqLi3Hq1Cmo1WoMHDhQ2qlN6VsAWjqdLdKoqChMnToVlZWVSExMREREBKKjo82RjYgMsH37drz55psoLS3FTz/9hLlz50pLnrp16yZzOuumc0F+bGwsFixYgLy8PGg0Gvz2t79FUlIStm3bZq6MRKSHkJAQ7N69W9p4vba2FpMmTeIO+WbQYtc+JiYGRUVFqKiowPnz56Uxlk8//VTagZuIlMPR0VHrFiiOjo5o06aNjIlsR4st0vr6etTU1CAxMRHLly+XzqvVanTu3Jm3MCBSiOTkZABAYWEhrl27hhEjRkCtViMrKwseHh7cRs8M9LodMxEpV3MhbUlMTIyZktguFlIiK1JVVYWCggI0NTWhT58+vKe9mXD3ESIrcfz4cYSFhSE9PR379u1DaGgojh49Kncsm8CBTiIrsW7dOuzatUta6nT58mXExMQgICBA5mTWjy1SIitx7949rfWi3bp1g0ajkTGR7WAhJbISzzzzDLZu3Yr6+nrU19dj69atre5RSk8OJ5uIrMT169eRkJCAvLw8iKIIHx8fxMfHw83NTe5oVo+FlIjISJxsIrJwgYGBrW4kxJvemR5bpEQWrrWb3gGt38uJngwWUiIrkpubi/z8fKjVavj6+sLX11fuSDaBs/ZEVmLt2rX45JNP4OHhAVdXV6xfvx6bNm2SO5ZNYIuUyEqEhIQgPT1d2gHqzp07iIyMxMGDB2VOZv3YIiWyEh06dMDNmzel48bGRmlvUjItztoTWbilS5cCADQaDcLCwhAYGAiVSoW///3v0q1GyLRYSIks3IABA7T+3+yll17i/dXMhIWUyMKFh4cDADZt2oTZs2drPfeXv/xFjkg2h5NNRBZuzZo1uH79OnJzcxEYGCidb2pqQkFBAbKzs2VMZxvYIiWycEFBQfj3v/+NvLw8re69SqXCvHnzZExmO9giJbISxcXF6NWrl9a5rKwsvP766zIlsh1c/kRkJebNm4dPPvkEAFBTU4MFCxZwQb6ZsEVKZCVqamrw/vvvo6SkBNevX8eECRMQFRUFlUoldzSrxxYpkZUQRRH29vZoaGiAKIoQBAF2dvwnbg78WyayEiEhIfDw8MDevXuxZ88enD17FqNHj5Y7lk1g157ISpw/fx69e/fWOnfo0CEMHz5cpkS2gy1SIivh6emJlJQUvP3226ivr0dycjKGDh0qdyybwEJKZCXee+89NDQ04Pz581CpVLh06RLi4+PljmUTWEiJrMS5c+fwhz/8AWq1Go6Ojli1ahWKiorkjmUTWEiJrIQgCLh79660UUl1dTU3LTETFlIiKxEVFYWpU6eisrISiYmJiIiIQHR0tNyxbAILKZGVOHLkCN577z3MnTsXzz77LDZu3IgDBw7IHcsmcPkTkYWLiYlBUVERKioq4ObmhuZ/0hqNBk8//TR2794tc0Lrx0JKZOHq6+tRU1ODxMRELF++XDqvVqvRuXNnqNXc5M3UWEiJiIzEMVIiIiOxkBIRGYmFlIjISCykRERGYiElIjLS/wcKlJAkWd0t9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature selction: remove highly correlated features\n",
    "# Filter Method: Spearman's Cross Correlation > 0.95\n",
    "# Make correlation matrix\n",
    "corr_matrix = X_train.corr(method = \"spearman\").abs()\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.set(font_scale = 1.0)\n",
    "f, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "f.tight_layout()\n",
    "plt.savefig(\"correlation_matrix.png\", dpi = 1080)\n",
    "\n",
    "# Select upper triangle of matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop features\n",
    "X_train = X_train.drop(to_drop, axis = 1)\n",
    "X_test = X_test.drop(to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning Random Forest. Go grab a beer or something.\n",
      "Fitting 2 folds for each of 1152 candidates, totalling 2304 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=2 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-befce6a35d0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Fit gscv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Now tuning {selected_classifier}. Go grab a beer or something.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mgscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Get best parameters and score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    334\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    666\u001b[0m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[0;32m    667\u001b[0m                              \u001b[1;34m\" number of members in each class.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m                              % (self.n_splits))\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             warnings.warn((\"The least populated class in y has only %d\"\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=2 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "# # Tuning a classifer to use with RFECV\n",
    "\n",
    "# Define classifier to use as the base of the recursive feature elimination algorithm\n",
    "selected_classifier = \"Random Forest\"\n",
    "classifier = classifiers[selected_classifier]\n",
    "\n",
    "# Tune classifier (Took = 4.8 minutes)\n",
    "    \n",
    "# Scale features via Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define steps in pipeline\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline = Pipeline(steps = steps)\n",
    "  \n",
    "# Define parameter grid\n",
    "param_grid = parameters[selected_classifier]\n",
    "\n",
    "# Initialize GridSearch object\n",
    "gscv = GridSearchCV(pipeline, param_grid, cv = 2, n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
    "# removed cv = 5 from original code\n",
    "                  \n",
    "# Fit gscv\n",
    "print(f\"Now tuning {selected_classifier}. Go grab a beer or something.\")\n",
    "gscv.fit(X_train, np.ravel(y_train))  \n",
    "\n",
    "# Get best parameters and score\n",
    "best_params = gscv.best_params_\n",
    "best_score = gscv.best_score_\n",
    "        \n",
    "# Update classifier parameters\n",
    "tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "classifier.set_params(**tuned_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Custom pipline object to use with RFECV\n",
    "# Select Features using RFECV\n",
    "class PipelineRFE(Pipeline):\n",
    "    # Source: https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 5 features.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-b4b0f0897f8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Fit RFECV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mfeature_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Get selected features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    550\u001b[0m         scores = parallel(\n\u001b[0;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    550\u001b[0m         scores = parallel(\n\u001b[0;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     return rfe._fit(\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-2aed055a1cad>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Source: https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPipelineRFE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# # Feature Selection: Recursive feature selction with cross validation\n",
    "# Define pipeline for RFECV\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "pipe = PipelineRFE(steps = steps)\n",
    "\n",
    "# Initialize RFECV object\n",
    "feature_selector = RFECV(pipe, cv = 5, step = 1, scoring = \"roc_auc\", verbose = 1)\n",
    "\n",
    "# Fit RFECV\n",
    "feature_selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get selected features\n",
    "feature_names = X_train.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-2b1614614f7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get Performance Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m performance_curve = {\"Number of Features\": list(range(1, len(feature_names) + 1)),\n\u001b[0m\u001b[0;32m      5\u001b[0m                     \"AUC\": feature_selector.grid_scores_}\n\u001b[0;32m      6\u001b[0m \u001b[0mperformance_curve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperformance_curve\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_names' is not defined"
     ]
    }
   ],
   "source": [
    "# # PERFORMANCE CURVE\n",
    "\n",
    "# Get Performance Data\n",
    "performance_curve = {\"Number of Features\": list(range(1, len(feature_names) + 1)),\n",
    "                    \"AUC\": feature_selector.grid_scores_}\n",
    "performance_curve = pd.DataFrame(performance_curve)\n",
    "\n",
    "# Performance vs Number of Features\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "colors = sns.color_palette(\"RdYlGn\", 20)\n",
    "line_color = colors[3]\n",
    "marker_colors = colors[-1]\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(figsize=(13, 6.5))\n",
    "sns.lineplot(x = \"Number of Features\", y = \"AUC\", data = performance_curve,\n",
    "             color = line_color, lw = 4, ax = ax)\n",
    "sns.regplot(x = performance_curve[\"Number of Features\"], y = performance_curve[\"AUC\"],\n",
    "            color = marker_colors, fit_reg = False, scatter_kws = {\"s\": 200}, ax = ax)\n",
    "\n",
    "# Axes limits\n",
    "plt.xlim(0.5, len(feature_names)+0.5)\n",
    "plt.ylim(0.60, 0.925)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axhline(y = 0.625, color = 'black', linewidth = 1.3, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"performance_curve.png\", dpi = 1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FEATURE SELECTION: RECURSIVE FEATURE SELECTION\n",
    "\n",
    "# Define pipeline for RFECV\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "pipe = PipelineRFE(steps = steps)\n",
    "\n",
    "# Initialize RFE object\n",
    "feature_selector = RFE(pipe, n_features_to_select = 10, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get selected features labels\n",
    "feature_names = X_train.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VUSUALIZING SELECTED FEATURE IMPORTANCE\n",
    "\n",
    "# Get selected features data set\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "# Train classifier\n",
    "classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_features, columns = [\"Feature Label\"])\n",
    "feature_importance[\"Feature Importance\"] = classifier.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Feature Importance\", ascending=False)\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.barplot(x = \"Feature Importance\", y = \"Feature Label\",\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 15)),  data = feature_importance)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"feature_importance.png\", dpi = 1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CLASSIFIER TUNING AND EVALUATION\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Tune and evaluate classifiers\n",
    "for classifier_label, classifier in classifiers.items():\n",
    "    # Print message to user\n",
    "    print(f\"Now tuning {classifier_label}.\")\n",
    "    \n",
    "    # Scale features via Z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Define steps in pipeline\n",
    "    steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "      \n",
    "    # Define parameter grid\n",
    "    param_grid = parameters[classifier_label]\n",
    "    \n",
    "    # Initialize GridSearch object\n",
    "    gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
    "                      \n",
    "    # Fit gscv\n",
    "    gscv.fit(X_train, np.ravel(y_train))  \n",
    "    \n",
    "    # Get best parameters and score\n",
    "    best_params = gscv.best_params_\n",
    "    best_score = gscv.best_score_\n",
    "    \n",
    "    # Update classifier parameters and define new pipeline with tuned classifier\n",
    "    tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "    classifier.set_params(**tuned_params)\n",
    "            \n",
    "    # Make predictions\n",
    "    if classifier_label in DECISION_FUNCTIONS:\n",
    "        y_pred = gscv.decision_function(X_test)\n",
    "    else:\n",
    "        y_pred = gscv.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Evaluate model\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Save results\n",
    "    result = {\"Classifier\": gscv,\n",
    "              \"Best Parameters\": best_params,\n",
    "              \"Training AUC\": best_score,\n",
    "              \"Test AUC\": auc}\n",
    "    \n",
    "    results.update({classifier_label: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VISUALING RESULTS\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "auc_scores = {\n",
    "              \"Classifier\": [],\n",
    "              \"AUC\": [],\n",
    "              \"AUC Type\": []\n",
    "              }\n",
    "\n",
    "# Get AUC scores into dictionary\n",
    "for classifier_label in results:\n",
    "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
    "                       \"AUC\": [results[classifier_label][\"Training AUC\"]] + auc_scores[\"AUC\"],\n",
    "                       \"AUC Type\": [\"Training\"] + auc_scores[\"AUC Type\"]})\n",
    "    \n",
    "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
    "                       \"AUC\": [results[classifier_label][\"Test AUC\"]] + auc_scores[\"AUC\"],\n",
    "                       \"AUC Type\": [\"Test\"] + auc_scores[\"AUC Type\"]})\n",
    "\n",
    "# Dictionary to PandasDataFrame\n",
    "auc_scores = pd.DataFrame(auc_scores)\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "    \n",
    "# Colors\n",
    "training_color = sns.color_palette(\"RdYlBu\", 10)[1]\n",
    "test_color = sns.color_palette(\"RdYlBu\", 10)[-2]\n",
    "colors = [training_color, test_color]\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "sns.barplot(x=\"AUC\", y=\"Classifier\", hue=\"AUC Type\", palette = colors,\n",
    "            data=auc_scores)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"AUC Scores.png\", dpi = 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
