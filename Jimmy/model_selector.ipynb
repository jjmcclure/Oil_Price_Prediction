{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading, visualizing, and preprocessing data\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklear.prepressing import Imputer\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  price    uup    gdp     prod  vader  textblob_polarity\n",
      "3045 2010-09-01  73.91  23.19  99.65  5562.00   0.26              -0.00\n",
      "3046 2010-09-02  75.02  23.17  99.65  5563.03   0.25              -0.01\n",
      "3047 2010-09-03  74.60  23.05  99.66  5564.07   0.25              -0.01\n",
      "3048 2010-09-04  74.47  23.11  99.66  5565.10   0.24              -0.02\n",
      "3049 2010-09-05  74.34  23.18  99.66  5566.13   0.23              -0.02\n",
      "      date\n",
      "price     \n",
      "73.91  NaT\n",
      "75.02  NaT\n",
      "74.60  NaT\n",
      "74.47  NaT\n",
      "74.34  NaT\n"
     ]
    }
   ],
   "source": [
    "file = Path('df_all.csv')\n",
    "s_path = Path('Data/df_all_2019_2020.csv')\n",
    "df_all_2019_2020 = pd.read_csv(file, parse_dates=True, infer_datetime_format=True)\n",
    "df_all_2019_2020 = df_all_2019_2020.loc[df_all_2019_2020['date'] >= '2010-09-01']\n",
    "df_all_2019_2020 = df_all_2019_2020.round(decimals=2)\n",
    "# df_all_2019_2020['date'] = pd.to_datetime(df_all_2019_2020['date']).apply(datetime.toordinal)\n",
    "df_all_2019_2020['date'] = pd.to_datetime(df_all_2019_2020['date'], format='%Y-%m-%d')\n",
    "# df_all_2019_2020['price'] = df_all_2019_2020.astype('int')\n",
    "print(df_all_2019_2020.head())\n",
    "df_price = pd.DataFrame(df_all_2019_2020['date'], df_all_2019_2020['price'])\n",
    "print(df_price.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 datetime64[ns]\n",
       "price                       float64\n",
       "uup                         float64\n",
       "gdp                         float64\n",
       "prod                        float64\n",
       "vader                       float64\n",
       "textblob_polarity           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_2019_2020.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "# X, y = make_classification(n_samples = 1000, n_features = 30, n_informative = 5,\n",
    "#                            n_redundant = 15, n_repeated = 5, \n",
    "#                            n_clusters_per_class = 2, class_sep = 0.5,\n",
    "#                            random_state = 1000, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "# Numpy array to pandas dataframe\n",
    "# labels = ['date', 'uup', 'gdp', 'prod', 'vader', 'textblob_polarity']\n",
    "X = df_all_2019_2020.drop(columns = 'price')\n",
    "y = df_all_2019_2020[\"price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,\n",
    "                                                    random_state = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of tuples with classifier label and classifier object\n",
    "classifiers = {}\n",
    "classifiers.update({\"LDA\": LinearDiscriminantAnalysis()})\n",
    "classifiers.update({\"QDA\": QuadraticDiscriminantAnalysis()})\n",
    "classifiers.update({\"AdaBoost\": AdaBoostClassifier()})\n",
    "classifiers.update({\"Bagging\": BaggingClassifier()})\n",
    "classifiers.update({\"Extra Trees Ensemble\": ExtraTreesClassifier()})\n",
    "classifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})\n",
    "classifiers.update({\"Random Forest\": RandomForestClassifier()})\n",
    "classifiers.update({\"Ridge\": RidgeClassifier()})\n",
    "classifiers.update({\"SGD\": SGDClassifier()})\n",
    "classifiers.update({\"BNB\": BernoulliNB()})\n",
    "classifiers.update({\"GNB\": GaussianNB()})\n",
    "classifiers.update({\"KNN\": KNeighborsClassifier()})\n",
    "classifiers.update({\"MLP\": MLPClassifier()})\n",
    "classifiers.update({\"LSVC\": LinearSVC()})\n",
    "classifiers.update({\"NuSVC\": NuSVC()})\n",
    "classifiers.update({\"SVC\": SVC()})\n",
    "classifiers.update({\"DTC\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ETC\": ExtraTreeClassifier()})\n",
    "\n",
    "# Create dict of decision function labels\n",
    "DECISION_FUNCTIONS = {\"Ridge\", \"SGD\", \"LSVC\", \"NuSVC\", \"SVC\"}\n",
    "\n",
    "# Create dict for classifiers with feature_importances_ attribute\n",
    "FEATURE_IMPORTANCE = {\"Gradient Boosting\", \"Extra Trees Ensemble\", \"Random Forest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "# Initiate parameter grid\n",
    "parameters = {}\n",
    "\n",
    "# Update dict with LDA\n",
    "parameters.update({\"LDA\": {\"classifier__solver\": [\"eigen\"], \n",
    "                                         }})    # switch from svd solver to eigen\n",
    "\n",
    "# Update dict with QDA\n",
    "parameters.update({\"QDA\": {\"classifier__reg_param\":[0.01*ii for ii in range(0, 101)], \n",
    "                                         }})  # this regs the per-class covariance estimates by transfroming S2 where\n",
    "                                              # S2 corresponds to the scaling attribute of a given class\n",
    "# Update dict with AdaBoost\n",
    "parameters.update({\"AdaBoost\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 1.0]\n",
    "                                 }})\n",
    "\n",
    "# Update dict with Bagging\n",
    "parameters.update({\"Bagging\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__max_features\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                \"classifier__n_jobs\": [-1] # using all processors, 1 none running in parallel\n",
    "                                }})\n",
    "\n",
    "# Update dict with Gradient Boosting\n",
    "parameters.update({\"Gradient Boosting\": { \n",
    "                                        \"classifier__learning_rate\":[0.15,0.1,0.05,0.01,0.005,0.001], \n",
    "                                        \"classifier__n_estimators\": [200],\n",
    "                                        \"classifier__max_depth\": [2,3,4,5,6],\n",
    "                                        \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"classifier__subsample\": [0.8, 0.9, 1]\n",
    "                                         }})\n",
    "\n",
    "\n",
    "# Update dict with Extra Trees\n",
    "parameters.update({\"Extra Trees Ensemble\": { \n",
    "                                            \"classifier__n_estimators\": [200],\n",
    "                                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                            \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                            \"classifier__n_jobs\": [-1]\n",
    "                                             }})\n",
    "\n",
    "\n",
    "# Update dict with Random Forest Parameters\n",
    "parameters.update({\"Random Forest\": { \n",
    "                                    \"classifier__n_estimators\": [200],\n",
    "                                    \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                    \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                    \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                    \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                    \"classifier__n_jobs\": [-1]\n",
    "                                     }})\n",
    "\n",
    "# Update dict with Ridge\n",
    "parameters.update({\"Ridge\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with SGD Classifier\n",
    "parameters.update({\"SGD\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0],\n",
    "                            \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with BernoulliNB Classifier\n",
    "parameters.update({\"BNB\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with GaussianNB Classifier\n",
    "parameters.update({\"GNB\": { \n",
    "                            \"classifier__var_smoothing\": [1e-9, 1e-8,1e-7, 1e-6, 1e-5]\n",
    "                             }})\n",
    "\n",
    "# Update dict with K Nearest Neighbors Classifier\n",
    "parameters.update({\"KNN\": { \n",
    "                            \"classifier__n_neighbors\": list(range(1,31)),\n",
    "                            \"classifier__p\": [1, 2, 3, 4, 5],\n",
    "                            \"classifier__leaf_size\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "# Update dict with MLPClassifier\n",
    "parameters.update({\"MLP\": { \n",
    "                            \"classifier__hidden_layer_sizes\": [(5), (10), (5,5), (10,10), (5,5,5), (10,10,10)],\n",
    "                            \"classifier__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                            \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                            \"classifier__max_iter\": [100, 200, 300, 500, 1000, 2000],\n",
    "                            \"classifier__alpha\": list(10.0 ** -np.arange(1, 10)),\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"LSVC\": { \n",
    "                            \"classifier__penalty\": [\"l2\"],\n",
    "                            \"classifier__C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"NuSVC\": { \n",
    "                            \"classifier__nu\": [0.25, 0.50, 0.75],\n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__degree\": [1,2,3,4,5,6],\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"SVC\": { \n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__gamma\": [\"auto\"],\n",
    "                            \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                            \"classifier__degree\": [1, 2, 3, 4, 5, 6]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with Decision Tree Classifier\n",
    "parameters.update({\"DTC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n",
    "# Update dict with Extra Tree Classifier\n",
    "parameters.update({\"ETC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature selction: remove highly correlated features\n",
    "# Filter Method: Spearman's Cross Correlation > 0.95\n",
    "# Make correlation matrix\n",
    "corr_matrix = X_train.corr(method = \"spearman\").abs()\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.set(font_scale = 1.0)\n",
    "f, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\n",
    "f.tight_layout()\n",
    "plt.savefig(\"correlation_matrix.png\", dpi = 1080)\n",
    "\n",
    "# Select upper triangle of matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop features\n",
    "X_train = X_train.drop(to_drop, axis = 1)\n",
    "X_test = X_test.drop(to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning Random Forest. Go grab a beer or something.\n",
      "           date    uup     gdp      prod  vader  textblob_polarity\n",
      "5822 2018-04-09  22.86  100.34  10659.00   0.40               0.42\n",
      "5590 2017-08-20  23.41   99.87   9549.00   0.29               0.38\n",
      "5095 2016-04-12  23.61  100.01   8792.00   0.13               0.16\n",
      "4564 2014-10-29  22.14  100.55   9072.26   0.38               0.37\n",
      "3313 2011-05-27  20.78   99.47   5595.58   0.11               0.17\n",
      "\n",
      "\n",
      "[ 63.42  47.75  42.17 ...  49.37 103.09  95.19]\n",
      "<class 'pandas.core.series.Series'>\n",
      "5822     63.42\n",
      "5590     47.75\n",
      "5095     42.17\n",
      "4564     82.20\n",
      "3313    100.59\n",
      "Name: price, dtype: float64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3d88c2d897b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mx_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mgscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# # gscv.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# # Tuning a classifer to use with RFECV\n",
    "\n",
    "# Define classifier to use as the base of the recursive feature elimination algorithm\n",
    "selected_classifier = \"Random Forest\"\n",
    "classifier = classifiers[selected_classifier]\n",
    "\n",
    "# Tune classifier (Took = 4.8 minutes)\n",
    "    \n",
    "# Scale features via Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define steps in pipeline\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline = Pipeline(steps = steps)\n",
    "  \n",
    "# Define parameter grid\n",
    "param_grid = parameters[selected_classifier]\n",
    "\n",
    "# Initialize GridSearch object\n",
    "gscv = GridSearchCV(pipeline, param_grid, cv = 2, n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
    "# removed cv = 5 from original code\n",
    "                  \n",
    "# Fit gscv\n",
    "print(f\"Now tuning {selected_classifier}. Go grab a beer or something.\")\n",
    "print(X_train.head())\n",
    "print(\"\\n\")\n",
    "print(np.ravel(y_train))\n",
    "print(type(y_train))\n",
    "print(y_train.head())\n",
    "x_scaled = scaler.transform(data)\n",
    "gscv.fit(x_scaled, np.ravel(X_train))\n",
    "# # gscv.fit(X_train, y_train) \n",
    "# # Get best parameters and score\n",
    "# best_params = gscv.best_params_\n",
    "# best_score = gscv.best_score_\n",
    "        \n",
    "# # Update classifier parameters\n",
    "# tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "# classifier.set_params(**tuned_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Custom pipline object to use with RFECV\n",
    "# Select Features using RFECV\n",
    "class PipelineRFE(Pipeline):\n",
    "    # Source: https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Selection: Recursive feature selction with cross validation\n",
    "# Define pipeline for RFECV\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "pipe = PipelineRFE(steps = steps)\n",
    "\n",
    "# Initialize RFECV object\n",
    "feature_selector = RFECV(pipe, cv = 5, step = 1, scoring = \"roc_auc\", verbose = 1)\n",
    "\n",
    "# Fit RFECV\n",
    "feature_selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get selected features\n",
    "feature_names = X_train.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PERFORMANCE CURVE\n",
    "\n",
    "# Get Performance Data\n",
    "performance_curve = {\"Number of Features\": list(range(1, len(feature_names) + 1)),\n",
    "                    \"AUC\": feature_selector.grid_scores_}\n",
    "performance_curve = pd.DataFrame(performance_curve)\n",
    "\n",
    "# Performance vs Number of Features\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "colors = sns.color_palette(\"RdYlGn\", 20)\n",
    "line_color = colors[3]\n",
    "marker_colors = colors[-1]\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(figsize=(13, 6.5))\n",
    "sns.lineplot(x = \"Number of Features\", y = \"AUC\", data = performance_curve,\n",
    "             color = line_color, lw = 4, ax = ax)\n",
    "sns.regplot(x = performance_curve[\"Number of Features\"], y = performance_curve[\"AUC\"],\n",
    "            color = marker_colors, fit_reg = False, scatter_kws = {\"s\": 200}, ax = ax)\n",
    "\n",
    "# Axes limits\n",
    "plt.xlim(0.5, len(feature_names)+0.5)\n",
    "plt.ylim(0.60, 0.925)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axhline(y = 0.625, color = 'black', linewidth = 1.3, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"performance_curve.png\", dpi = 1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FEATURE SELECTION: RECURSIVE FEATURE SELECTION\n",
    "\n",
    "# Define pipeline for RFECV\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "pipe = PipelineRFE(steps = steps)\n",
    "\n",
    "# Initialize RFE object\n",
    "feature_selector = RFE(pipe, n_features_to_select = 10, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get selected features labels\n",
    "feature_names = X_train.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VUSUALIZING SELECTED FEATURE IMPORTANCE\n",
    "\n",
    "# Get selected features data set\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "# Train classifier\n",
    "classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_features, columns = [\"Feature Label\"])\n",
    "feature_importance[\"Feature Importance\"] = classifier.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Feature Importance\", ascending=False)\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.barplot(x = \"Feature Importance\", y = \"Feature Label\",\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 15)),  data = feature_importance)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"feature_importance.png\", dpi = 1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CLASSIFIER TUNING AND EVALUATION\n",
    "\n",
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Tune and evaluate classifiers\n",
    "for classifier_label, classifier in classifiers.items():\n",
    "    # Print message to user\n",
    "    print(f\"Now tuning {classifier_label}.\")\n",
    "    \n",
    "    # Scale features via Z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Define steps in pipeline\n",
    "    steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "      \n",
    "    # Define parameter grid\n",
    "    param_grid = parameters[classifier_label]\n",
    "    \n",
    "    # Initialize GridSearch object\n",
    "    gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
    "                      \n",
    "    # Fit gscv\n",
    "    gscv.fit(X_train, np.ravel(y_train))  \n",
    "    \n",
    "    # Get best parameters and score\n",
    "    best_params = gscv.best_params_\n",
    "    best_score = gscv.best_score_\n",
    "    \n",
    "    # Update classifier parameters and define new pipeline with tuned classifier\n",
    "    tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "    classifier.set_params(**tuned_params)\n",
    "            \n",
    "    # Make predictions\n",
    "    if classifier_label in DECISION_FUNCTIONS:\n",
    "        y_pred = gscv.decision_function(X_test)\n",
    "    else:\n",
    "        y_pred = gscv.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Evaluate model\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Save results\n",
    "    result = {\"Classifier\": gscv,\n",
    "              \"Best Parameters\": best_params,\n",
    "              \"Training AUC\": best_score,\n",
    "              \"Test AUC\": auc}\n",
    "    \n",
    "    results.update({classifier_label: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VISUALING RESULTS\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "auc_scores = {\n",
    "              \"Classifier\": [],\n",
    "              \"AUC\": [],\n",
    "              \"AUC Type\": []\n",
    "              }\n",
    "\n",
    "# Get AUC scores into dictionary\n",
    "for classifier_label in results:\n",
    "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
    "                       \"AUC\": [results[classifier_label][\"Training AUC\"]] + auc_scores[\"AUC\"],\n",
    "                       \"AUC Type\": [\"Training\"] + auc_scores[\"AUC Type\"]})\n",
    "    \n",
    "    auc_scores.update({\"Classifier\": [classifier_label] + auc_scores[\"Classifier\"],\n",
    "                       \"AUC\": [results[classifier_label][\"Test AUC\"]] + auc_scores[\"AUC\"],\n",
    "                       \"AUC Type\": [\"Test\"] + auc_scores[\"AUC Type\"]})\n",
    "\n",
    "# Dictionary to PandasDataFrame\n",
    "auc_scores = pd.DataFrame(auc_scores)\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "    \n",
    "# Colors\n",
    "training_color = sns.color_palette(\"RdYlBu\", 10)[1]\n",
    "test_color = sns.color_palette(\"RdYlBu\", 10)[-2]\n",
    "colors = [training_color, test_color]\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "sns.barplot(x=\"AUC\", y=\"Classifier\", hue=\"AUC Type\", palette = colors,\n",
    "            data=auc_scores)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"AUC Scores.png\", dpi = 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
